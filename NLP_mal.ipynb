{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thedh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\thedh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thedh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\thedh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import \tWordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"don\\'t\", \"do not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16214\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAL_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genres</th>\n",
       "      <th>sypnopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>8.78</td>\n",
       "      <td>Action, Adventure, Comedy, Drama, Sci-Fi, Space</td>\n",
       "      <td>In the year 2071, humanity has colonized sever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
       "      <td>8.39</td>\n",
       "      <td>Action, Drama, Mystery, Sci-Fi, Space</td>\n",
       "      <td>other day, another bounty—such is the life of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Trigun</td>\n",
       "      <td>8.24</td>\n",
       "      <td>Action, Sci-Fi, Adventure, Comedy, Drama, Shounen</td>\n",
       "      <td>Vash the Stampede is the man with a $$60,000,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Witch Hunter Robin</td>\n",
       "      <td>7.27</td>\n",
       "      <td>Action, Mystery, Police, Supernatural, Drama, ...</td>\n",
       "      <td>ches are individuals with special powers like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Bouken Ou Beet</td>\n",
       "      <td>6.98</td>\n",
       "      <td>Adventure, Fantasy, Shounen, Supernatural</td>\n",
       "      <td>It is the dark century and the people are suff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>Eyeshield 21</td>\n",
       "      <td>7.95</td>\n",
       "      <td>Action, Sports, Comedy, Shounen</td>\n",
       "      <td>Sena is like any other shy kid starting high s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>Hachimitsu to Clover</td>\n",
       "      <td>8.06</td>\n",
       "      <td>Comedy, Drama, Josei, Romance, Slice of Life</td>\n",
       "      <td>Yuuta Takemoto, a sophomore at an arts college...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>Hungry Heart: Wild Striker</td>\n",
       "      <td>7.59</td>\n",
       "      <td>Slice of Life, Comedy, Sports, Shounen</td>\n",
       "      <td>Kyosuke Kano has lived under the shadow of his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>Initial D Fourth Stage</td>\n",
       "      <td>8.15</td>\n",
       "      <td>Action, Cars, Sports, Drama, Seinen</td>\n",
       "      <td>Takumi Fujiwara finally joins Ryousuke and Kei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>Monster</td>\n",
       "      <td>8.76</td>\n",
       "      <td>Drama, Horror, Mystery, Police, Psychological,...</td>\n",
       "      <td>Dr. Kenzou Tenma, an elite neurosurgeon recent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MAL_ID                             Name Score  \\\n",
       "0       1                     Cowboy Bebop  8.78   \n",
       "1       5  Cowboy Bebop: Tengoku no Tobira  8.39   \n",
       "2       6                           Trigun  8.24   \n",
       "3       7               Witch Hunter Robin  7.27   \n",
       "4       8                   Bouken Ou Beet  6.98   \n",
       "5      15                     Eyeshield 21  7.95   \n",
       "6      16             Hachimitsu to Clover  8.06   \n",
       "7      17       Hungry Heart: Wild Striker  7.59   \n",
       "8      18           Initial D Fourth Stage  8.15   \n",
       "9      19                          Monster  8.76   \n",
       "\n",
       "                                              Genres  \\\n",
       "0    Action, Adventure, Comedy, Drama, Sci-Fi, Space   \n",
       "1              Action, Drama, Mystery, Sci-Fi, Space   \n",
       "2  Action, Sci-Fi, Adventure, Comedy, Drama, Shounen   \n",
       "3  Action, Mystery, Police, Supernatural, Drama, ...   \n",
       "4          Adventure, Fantasy, Shounen, Supernatural   \n",
       "5                    Action, Sports, Comedy, Shounen   \n",
       "6       Comedy, Drama, Josei, Romance, Slice of Life   \n",
       "7             Slice of Life, Comedy, Sports, Shounen   \n",
       "8                Action, Cars, Sports, Drama, Seinen   \n",
       "9  Drama, Horror, Mystery, Police, Psychological,...   \n",
       "\n",
       "                                           sypnopsis  \n",
       "0  In the year 2071, humanity has colonized sever...  \n",
       "1  other day, another bounty—such is the life of ...  \n",
       "2  Vash the Stampede is the man with a $$60,000,0...  \n",
       "3  ches are individuals with special powers like ...  \n",
       "4  It is the dark century and the people are suff...  \n",
       "5  Sena is like any other shy kid starting high s...  \n",
       "6  Yuuta Takemoto, a sophomore at an arts college...  \n",
       "7  Kyosuke Kano has lived under the shadow of his...  \n",
       "8  Takumi Fujiwara finally joins Ryousuke and Kei...  \n",
       "9  Dr. Kenzou Tenma, an elite neurosurgeon recent...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"anime_with_synopsis.csv\")\n",
    "print(len(df))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MAL_ID', 'Name', 'Score', 'Genres', 'sypnopsis'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MAL_ID                                               Name    Score  \\\n",
      "1347    1547                                   Obake no Q-tarou  Unknown   \n",
      "1439    1656                                    PostPet Momobin  Unknown   \n",
      "1512    1739                         Shibawanko no Wa no Kokoro  Unknown   \n",
      "1619    1863                            Silk Road Shounen Yuuto  Unknown   \n",
      "1808    2073  Hengen Taima Yakou Karura Mau! Sendai Kokeshi ...  Unknown   \n",
      "\n",
      "                                           Genres  \\\n",
      "1347  Comedy, School, Slice of Life, Supernatural   \n",
      "1439                                 Comedy, Kids   \n",
      "1512                                         Kids   \n",
      "1619               Adventure, Fantasy, Historical   \n",
      "1808                               Horror, Shoujo   \n",
      "\n",
      "                                              sypnopsis  \n",
      "1347  Q-taro, a monster, is living with the Ohara fa...  \n",
      "1439  omo and Komomo can deliver mail from anyone, t...  \n",
      "1512  Based on a japanese children`s book by Yoshie ...  \n",
      "1619  hen a boy Yuto visits Qinghai in China, he is ...  \n",
      "1808  Shoko and Maiko Ougi are apparently two ordina...  \n",
      "      MAL_ID                                            Name Score  \\\n",
      "2225    2626  The☆Doraemons: Mushimushi Pyonpyon Daisakusen!  6.27   \n",
      "2226    2627                        Doraemon: It's New Year!  6.49   \n",
      "2227    2628        The☆Doraemons: Strange, Sweets, Strange?  6.29   \n",
      "2228    2629                    Doraemon and Itchy the Stray  6.35   \n",
      "2231    2632            Doraemon: Time Machine de Oshougatsu  6.41   \n",
      "\n",
      "                                        Genres  \\\n",
      "2225                                   Fantasy   \n",
      "2226             Kids, Comedy, Sci-Fi, Shounen   \n",
      "2227                                   Fantasy   \n",
      "2228             Comedy, Kids, Sci-Fi, Shounen   \n",
      "2231  Sci-Fi, Adventure, Comedy, Kids, Shounen   \n",
      "\n",
      "                                              sypnopsis  \n",
      "2225  No synopsis information has been added to this...  \n",
      "2226  No synopsis information has been added to this...  \n",
      "2227  No synopsis information has been added to this...  \n",
      "2228  No synopsis information has been added to this...  \n",
      "2231  No synopsis information has been added to this...  \n",
      "Length after Removing Unknow entries: 10915\n"
     ]
    }
   ],
   "source": [
    "#Data Cleaning\n",
    "# Drop all the rows with Unknown in the 'Score' column\n",
    "print(df[df['Score'] == 'Unknown'].head(5))\n",
    "df = df[df['Score'] != 'Unknown']\n",
    "# Drop all the rows with no synopsis information\n",
    "print(df[df['sypnopsis'] == 'No synopsis information has been added to this title. Help improve our database by adding a synopsis here .'].head(5))\n",
    "df = df[df['sypnopsis'] != 'No synopsis information has been added to this title. Help improve our database by adding a synopsis here .']\n",
    "print(f\"Length after Removing Unknow entries: {len(df)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAL_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genres</th>\n",
       "      <th>sypnopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>8.78</td>\n",
       "      <td>Action, Adventure, Comedy, Drama, Sci-Fi, Space</td>\n",
       "      <td>In the year 2071, humanity has colonized sever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
       "      <td>8.39</td>\n",
       "      <td>Action, Drama, Mystery, Sci-Fi, Space</td>\n",
       "      <td>other day, another bounty—such is the life of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Trigun</td>\n",
       "      <td>8.24</td>\n",
       "      <td>Action, Sci-Fi, Adventure, Comedy, Drama, Shounen</td>\n",
       "      <td>Vash the Stampede is the man with a $$60,000,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Witch Hunter Robin</td>\n",
       "      <td>7.27</td>\n",
       "      <td>Action, Mystery, Police, Supernatural, Drama, ...</td>\n",
       "      <td>ches are individuals with special powers like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Bouken Ou Beet</td>\n",
       "      <td>6.98</td>\n",
       "      <td>Adventure, Fantasy, Shounen, Supernatural</td>\n",
       "      <td>It is the dark century and the people are suff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>Eyeshield 21</td>\n",
       "      <td>7.95</td>\n",
       "      <td>Action, Sports, Comedy, Shounen</td>\n",
       "      <td>Sena is like any other shy kid starting high s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>Hachimitsu to Clover</td>\n",
       "      <td>8.06</td>\n",
       "      <td>Comedy, Drama, Josei, Romance, Slice of Life</td>\n",
       "      <td>Yuuta Takemoto, a sophomore at an arts college...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>Hungry Heart: Wild Striker</td>\n",
       "      <td>7.59</td>\n",
       "      <td>Slice of Life, Comedy, Sports, Shounen</td>\n",
       "      <td>Kyosuke Kano has lived under the shadow of his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>Initial D Fourth Stage</td>\n",
       "      <td>8.15</td>\n",
       "      <td>Action, Cars, Sports, Drama, Seinen</td>\n",
       "      <td>Takumi Fujiwara finally joins Ryousuke and Kei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>Monster</td>\n",
       "      <td>8.76</td>\n",
       "      <td>Drama, Horror, Mystery, Police, Psychological,...</td>\n",
       "      <td>Dr. Kenzou Tenma, an elite neurosurgeon recent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MAL_ID                             Name  Score  \\\n",
       "0       1                     Cowboy Bebop   8.78   \n",
       "1       5  Cowboy Bebop: Tengoku no Tobira   8.39   \n",
       "2       6                           Trigun   8.24   \n",
       "3       7               Witch Hunter Robin   7.27   \n",
       "4       8                   Bouken Ou Beet   6.98   \n",
       "5      15                     Eyeshield 21   7.95   \n",
       "6      16             Hachimitsu to Clover   8.06   \n",
       "7      17       Hungry Heart: Wild Striker   7.59   \n",
       "8      18           Initial D Fourth Stage   8.15   \n",
       "9      19                          Monster   8.76   \n",
       "\n",
       "                                              Genres  \\\n",
       "0    Action, Adventure, Comedy, Drama, Sci-Fi, Space   \n",
       "1              Action, Drama, Mystery, Sci-Fi, Space   \n",
       "2  Action, Sci-Fi, Adventure, Comedy, Drama, Shounen   \n",
       "3  Action, Mystery, Police, Supernatural, Drama, ...   \n",
       "4          Adventure, Fantasy, Shounen, Supernatural   \n",
       "5                    Action, Sports, Comedy, Shounen   \n",
       "6       Comedy, Drama, Josei, Romance, Slice of Life   \n",
       "7             Slice of Life, Comedy, Sports, Shounen   \n",
       "8                Action, Cars, Sports, Drama, Seinen   \n",
       "9  Drama, Horror, Mystery, Police, Psychological,...   \n",
       "\n",
       "                                           sypnopsis  \n",
       "0  In the year 2071, humanity has colonized sever...  \n",
       "1  other day, another bounty—such is the life of ...  \n",
       "2  Vash the Stampede is the man with a $$60,000,0...  \n",
       "3  ches are individuals with special powers like ...  \n",
       "4  It is the dark century and the people are suff...  \n",
       "5  Sena is like any other shy kid starting high s...  \n",
       "6  Yuuta Takemoto, a sophomore at an arts college...  \n",
       "7  Kyosuke Kano has lived under the shadow of his...  \n",
       "8  Takumi Fujiwara finally joins Ryousuke and Kei...  \n",
       "9  Dr. Kenzou Tenma, an elite neurosurgeon recent...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turing Score into float\n",
    "df['Score'] = df['Score'].astype(float)\n",
    "df['sypnopsis'] = df['sypnopsis'].astype(str)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# df[\"tokenized\"] = \"\"\n",
    "# for i in range(len(df)):\n",
    "#     df.loc[i,'sypnopsis'] = df.loc[i,'sypnopsis'].lower()\n",
    "#     df.loc[i,'sypnopsis'] = decontracted(df.loc[i,'sypnopsis'])\n",
    "#     word_tokens = tokenizer.tokenize(df.loc[i,'sypnopsis'])\n",
    "#     lemmatized_tokens = [wordnet_lemmatizer.lemmatize(w) for w in word_tokens]\n",
    "#     filtered_sentence = [w for w in lemmatized_tokens if not w in stop_words and not w.isdigit()]\n",
    "#     df.loc[i,'tokenized'] = \" \".join(filtered_sentence)\n",
    "# df[\"tokenized\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from gensim.models import Word2Vec\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df['tokenized'].astype(str), df['Score'], test_size=0.25, random_state=42)\n",
    "# # print(X_train)\n",
    "# # print(\"--------------------\")\n",
    "# # print(X_test)\n",
    "\n",
    "# # Preprocess the synopsis text data\n",
    "# vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
    "# vectorizer.fit(X_train)\n",
    "# X_train = vectorizer.transform(X_train)\n",
    "# # X_train = vectorizer.transform(X_train)\n",
    "\n",
    "# X_test = vectorizer.transform(X_test)\n",
    "# # X = vectorizer.fit_transform(df['tokenized'].values.astype('U'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import r2_score\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# # Define the MLP model\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "# # Random siliness cause parameter tuning sucks\n",
    "# model = Sequential()\n",
    "# model.add(Dense(4, input_dim=X_train.shape[1], activation='tanh'))\n",
    "# model.add(Dense(4, activation='tanh'))\n",
    "# model.add(Dense(4, activation='tanh'))\n",
    "# # model.add(Dense(4, activation='tanh'))\n",
    "# # model.add(Dense(3, activation='tanh'))\n",
    "\n",
    "# # Add an output layer\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# # Compile the model\n",
    "# # compile model with sgd and nesterov momentum\n",
    "# model.compile(loss='mse', optimizer=\"sgd\") # mean squared error\n",
    "# # Train the model\n",
    "# total_epochs = 100\n",
    "\n",
    "# history = model.fit(X_train.toarray(), y_train, validation_data=(X_val.toarray(), y_val), epochs=total_epochs, batch_size=32, verbose=1)\n",
    "\n",
    "# # Predict on the test set\n",
    "# predictions = model.predict(X_test.toarray())\n",
    "\n",
    "# # Calculate the R^2 score\n",
    "# r2 = r2_score(y_test, predictions)\n",
    "# print('R^2 Score:', r2)\n",
    "\n",
    "# # Evaluate the model\n",
    "# mse = mean_squared_error(y_test, predictions)\n",
    "# print('Mean Squared Error:', mse)\n",
    "\n",
    "# # Evaluate the mean absolute error\n",
    "# mae = mean_absolute_error(y_test, predictions)\n",
    "# print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = range(1, total_epochs+1)\n",
    "# loss_train = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "# plt.plot(loss_train)\n",
    "# plt.plot(val_loss)\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df['sentiment_score'] = df['sypnopsis'].apply(lambda text: sia.polarity_scores(text)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>sypnopsis</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.78</td>\n",
       "      <td>In the year 2071, humanity has colonized sever...</td>\n",
       "      <td>0.9402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.39</td>\n",
       "      <td>other day, another bounty—such is the life of ...</td>\n",
       "      <td>-0.9246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.24</td>\n",
       "      <td>Vash the Stampede is the man with a $$60,000,0...</td>\n",
       "      <td>-0.9728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.27</td>\n",
       "      <td>ches are individuals with special powers like ...</td>\n",
       "      <td>-0.0516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.98</td>\n",
       "      <td>It is the dark century and the people are suff...</td>\n",
       "      <td>-0.9578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.95</td>\n",
       "      <td>Sena is like any other shy kid starting high s...</td>\n",
       "      <td>0.8767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.06</td>\n",
       "      <td>Yuuta Takemoto, a sophomore at an arts college...</td>\n",
       "      <td>0.9674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.59</td>\n",
       "      <td>Kyosuke Kano has lived under the shadow of his...</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.15</td>\n",
       "      <td>Takumi Fujiwara finally joins Ryousuke and Kei...</td>\n",
       "      <td>0.9744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.76</td>\n",
       "      <td>Dr. Kenzou Tenma, an elite neurosurgeon recent...</td>\n",
       "      <td>-0.9880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                          sypnopsis  sentiment_score\n",
       "0   8.78  In the year 2071, humanity has colonized sever...           0.9402\n",
       "1   8.39  other day, another bounty—such is the life of ...          -0.9246\n",
       "2   8.24  Vash the Stampede is the man with a $$60,000,0...          -0.9728\n",
       "3   7.27  ches are individuals with special powers like ...          -0.0516\n",
       "4   6.98  It is the dark century and the people are suff...          -0.9578\n",
       "5   7.95  Sena is like any other shy kid starting high s...           0.8767\n",
       "6   8.06  Yuuta Takemoto, a sophomore at an arts college...           0.9674\n",
       "7   7.59  Kyosuke Kano has lived under the shadow of his...           0.4404\n",
       "8   8.15  Takumi Fujiwara finally joins Ryousuke and Kei...           0.9744\n",
       "9   8.76  Dr. Kenzou Tenma, an elite neurosurgeon recent...          -0.9880"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Genres', 'Name', 'MAL_ID'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R^2: -2.0234588804816456e+16\n",
      "Test MSE: 1.7506284838573914e+16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "# Vectorize the synopsis column\n",
    "synopsis_vectors = vectorizer.fit_transform(df['sypnopsis']).toarray()\n",
    "\n",
    "# Combine the CountVectorizer vectors with the other features\n",
    "other_features = df.drop(columns=['sypnopsis', 'Score']).values\n",
    "X = np.concatenate([other_features, synopsis_vectors], axis=1)\n",
    "\n",
    "# Get the labels\n",
    "y = df['Score'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the LinearRegression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2 = model.score(X_test, y_test)\n",
    "print(f'Test R^2: {r2}')\n",
    "\n",
    "# Calculate the mean squared error of the predictions\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Test MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "# # Preprocess the synopsis text data\n",
    "# vectorizer = CountVectorizer(max_features=20000, ngram_range=(1, 2))\n",
    "# vectorizer.fit(df['tokenized'])\n",
    "# X = vectorizer.transform(df['tokenized'])\n",
    "# X_sentiment = hstack((X, df['sentiment_score'].values[:, None]))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_sentiment, df['Score'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sypnopsis</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>Score_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the year 2071, humanity has colonized sever...</td>\n",
       "      <td>0.9402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other day, another bounty—such is the life of ...</td>\n",
       "      <td>-0.9246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vash the Stampede is the man with a $$60,000,0...</td>\n",
       "      <td>-0.9728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ches are individuals with special powers like ...</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is the dark century and the people are suff...</td>\n",
       "      <td>-0.9578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sena is like any other shy kid starting high s...</td>\n",
       "      <td>0.8767</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yuuta Takemoto, a sophomore at an arts college...</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kyosuke Kano has lived under the shadow of his...</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Takumi Fujiwara finally joins Ryousuke and Kei...</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Kenzou Tenma, an elite neurosurgeon recent...</td>\n",
       "      <td>-0.9880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sypnopsis  sentiment_score  \\\n",
       "0  In the year 2071, humanity has colonized sever...           0.9402   \n",
       "1  other day, another bounty—such is the life of ...          -0.9246   \n",
       "2  Vash the Stampede is the man with a $$60,000,0...          -0.9728   \n",
       "3  ches are individuals with special powers like ...          -0.0516   \n",
       "4  It is the dark century and the people are suff...          -0.9578   \n",
       "5  Sena is like any other shy kid starting high s...           0.8767   \n",
       "6  Yuuta Takemoto, a sophomore at an arts college...           0.9674   \n",
       "7  Kyosuke Kano has lived under the shadow of his...           0.4404   \n",
       "8  Takumi Fujiwara finally joins Ryousuke and Kei...           0.9744   \n",
       "9  Dr. Kenzou Tenma, an elite neurosurgeon recent...          -0.9880   \n",
       "\n",
       "   Score_Class  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            0  \n",
       "5            1  \n",
       "6            1  \n",
       "7            1  \n",
       "8            1  \n",
       "9            1  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Score_Class'] = df['Score'].apply(lambda x: 1 if x >= 7.0 else 0)\n",
    "df = df.drop(columns=['Score'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertModel, BertTokenizer\n",
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from scipy.sparse import hstack\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# import torch\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import r2_score\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# # Load BERT model and tokenizer\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # Tokenize and encode the 'synopsis' column\n",
    "# tokens = df['sypnopsis'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True))\n",
    "# max_len = max(map(len, tokens))\n",
    "# padded_tokens = np.array([i + [0]*(max_len-len(i)) for i in tokens.values])\n",
    "# attention_mask = np.where(padded_tokens != 0, 1, 0)\n",
    "# input_ids = torch.tensor(padded_tokens)  \n",
    "# attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# # Get BERT embeddings\n",
    "# features = last_hidden_states[0][:,0,:].numpy()\n",
    "\n",
    "# # Perform sentiment analysis\n",
    "# sia = SentimentIntensityAnalyzer()\n",
    "# df['sentiment_score'] = df['sypnopsis'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "# # Combine BERT embeddings and sentiment scores\n",
    "# X = hstack((features, df['sentiment_score'].values[:, None]))\n",
    "\n",
    "# # Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, df['Score'], test_size=0.25, random_state=42)\n",
    "\n",
    "# # Train MLPRegressor\n",
    "# regressor = MLPRegressor(random_state=42)\n",
    "# regressor.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the model\n",
    "# y_pred = regressor.predict(X_test)\n",
    "\n",
    "# # Calculate the R^2 score\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# print('R^2 Score:', r2)\n",
    "\n",
    "# # Evaluate the mean squared error\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print('Mean Squared Error:', mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Data adapters should be mutually exclusive for handling inputs. Found multiple adapters [<class 'keras.src.engine.data_adapter.TensorLikeDataAdapter'>, <class 'keras.src.engine.data_adapter.GeneratorDataAdapter'>] to handle input: <class 'pandas.core.frame.DataFrame'>, <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_hinge\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnadam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Train the model with validation data\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m     45\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\thedh\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\thedh\\miniconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1111\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle input: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1107\u001b[0m             _type_name(x), _type_name(y)\n\u001b[0;32m   1108\u001b[0m         )\n\u001b[0;32m   1109\u001b[0m     )\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[0;32m   1115\u001b[0m     )\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;66;03m# Instrument the data adapter usage before returning it\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m keras_data_adapter_gauge\u001b[38;5;241m.\u001b[39mget_cell(adapter_cls[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Data adapters should be mutually exclusive for handling inputs. Found multiple adapters [<class 'keras.src.engine.data_adapter.TensorLikeDataAdapter'>, <class 'keras.src.engine.data_adapter.GeneratorDataAdapter'>] to handle input: <class 'pandas.core.frame.DataFrame'>, <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "# Vectorize the synopsis column\n",
    "synopsis_vectors = vectorizer.fit_transform(df['sypnopsis'])\n",
    "\n",
    "# Convert the vectorized data into a DataFrame\n",
    "synopsis_df = pd.DataFrame(synopsis_vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Combine the CountVectorizer vectors with the other features\n",
    "other_features = df.drop(columns=['sypnopsis', 'Score_Class'])\n",
    "X = pd.concat([other_features.reset_index(drop=True), synopsis_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Get the labels\n",
    "y = df['Score_Class'].values\n",
    "\n",
    "# Split the data into training, testing, and validation sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)  # 70% for training\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 15% for validation, 15% for testing\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='tanh', kernel_regularizer=regularizers.l2(0.002), input_shape=(X_train.shape[1],)),\n",
    "    # tf.keras.layers.Dense(64, activation=custom_leaky_relu, kernel_regularizer=regularizers.l2(0.001)),\n",
    "    # tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.005)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_hinge', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train the model with validation data\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "# loss, accuracy = model.evaluate(X, y)\n",
    "# print('Accuracy:', accuracy)\n",
    "\n",
    "# # classificaiton report\n",
    "# y_pred = model.predict(X)\n",
    "# y_pred = (y_pred > 0.5).astype(int)\n",
    "# print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.layers import Embedding, SimpleRNN\n",
    "# from tensorflow.keras.layers import LSTM\n",
    "# from tensorflow.keras.layers import Dropout\n",
    "# from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "# # Preprocess the synopsis text data\n",
    "# tokenizer = Tokenizer(num_words=1000)\n",
    "# tokenizer.fit_on_texts(df['sypnopsis'].values.astype('U'))\n",
    "# sequences = tokenizer.texts_to_sequences(df['sypnopsis'].values.astype('U'))\n",
    "\n",
    "# # Pad the sequences\n",
    "# X = pad_sequences(sequences)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, df['Score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# # Define the LSTM model with dropout and regularization\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(1000, 32))\n",
    "# model.add(LSTM(64, return_sequences=True, kernel_regularizer=regularizers.l2(0.01)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(LSTM(64, kernel_regularizer=regularizers.l2(0.01)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(loss='mean_squared_error', optimizer=\"adam\")\n",
    "\n",
    "# # Train the model\n",
    "# total_epochs = 20\n",
    "# history = model.fit(X_train, y_train, epochs=total_epochs, batch_size=64, verbose=1)\n",
    "\n",
    "# # Predict on the test set\n",
    "# predictions = model.predict(X_test)\n",
    "\n",
    "# # Calculate the R^2 score\n",
    "# r2 = r2_score(y_test, predictions)\n",
    "# print('R^2 Score:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df['tokenized'].astype(str), df['Score'], test_size=0.25, random_state=42)\n",
    "# print(len(X_train))\n",
    "\n",
    "# w2v_model = Word2Vec(min_count=2, window=3, vector_size=1500, workers=4)\n",
    "# w2v_model.build_vocab(df['tokenized'])\n",
    "# w2v_model.train(df['tokenized'], total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "# def vectorize(list_of_tokens):\n",
    "#     vector = []\n",
    "#     for tokens in list_of_tokens:\n",
    "#         sum = 0\n",
    "#         n = 0\n",
    "#         for token in tokens:\n",
    "#             try:\n",
    "#                 sum += w2v_model.wv[token]\n",
    "#             except KeyError:\n",
    "#                 sum += 0\n",
    "#             finally:\n",
    "#                 n += 1\n",
    "#         vector.append(sum/n)\n",
    "#     return vector\n",
    "\n",
    "# X_train = vectorize(X_train)\n",
    "# X_test = vectorize(X_test)\n",
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write code to plot the distribution of scores showing mean and median scores\n",
    "# plt.hist(df['Score'], bins=20)\n",
    "# plt.axvline(df['Score'].mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "# plt.axvline(df['Score'].median(), color='r', linestyle='dashed', linewidth=1)\n",
    "# plt.xlabel('Score')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distribution of Scores')\n",
    "# plt.legend(['Mean', 'Median'])\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
